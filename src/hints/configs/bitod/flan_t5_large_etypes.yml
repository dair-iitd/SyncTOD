experiment_name: bitod_t5_large_etypes
destpath: ./runs/bitod_t5_large_etypes/
datapath: ../data/BiTOD/
dataset_name: BiTOD
hint: entity_types

model:
  max_input_length: 1024
  wildcard: 'google/flan-t5-large'
  use_kb: true
  ctx_format: text

train:
  # per_device_train_batch_size: 8
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 8
  # gradient_checkpointing: true
  learning_rate: 0.0001
  num_epochs: 5
  seed: 42
  fp16: False
  save_eval_steps: 800
  resume_training: False
  save_total_limit: 2
  metric_for_best_model: f1
  greater_is_better: True
  early_stopping_patience: 5
  warmup_ratio: 0.1

dev:
  per_device_eval_batch_size: 4
  sample: False
  num_beams: 1
  max_resp_length: 128
  top_k: 8
  top_p: 0.9
  temperature: 0.85

use_wandb: True
